---
title: "Technical Report for Supervisor"
author: "Amir A. Seid"
date: "2026-02-11"
output:
  html_document:
    theme: cosmo
  pdf_document:
    number_sections: true
  word_document:
    toc: true
    number_sections: true
    highlight_style: "printing"
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, include = FALSE)
```

```{r}
library(MASS)
library(naniar)
library(mice)
library(brant)
library(VGAM)
library(tidyverse)
library(caret)
library(kableExtra)
library(patchwork)
library(gtsummary)

conflicted::conflicts_prefer(dplyr::select)
conflicted::conflicts_prefer(dplyr::filter)
conflicted::conflicts_prefer(dplyr::arrange)

PATH = "CSV_datasets/Heart_failure.csv"
```

```{r for EDA vizplots}
                                              #### ----- To create tables for Report ---- ####
df <- read.csv(PATH)

#Formatting NA values
df <- df %>% 
  mutate(across(
    .cols = everything(),
    function(x){
      case_when(x %in% c("?", "-9") ~ NA,
                TRUE ~ x)
    }
  )) %>% 
  mutate(across(
    .cols = everything(), as.numeric
  ))

# Converting to categorical variables
df <- df %>% 
  mutate(
    across(
      .cols = c("sex", "fbs", "restecg", "exang", "cp"),
      ~ factor(.)
    )
  )

df$num = factor(df$num, levels = c(0, 1, 2, 3, 4), ordered = T)

df <- df %>% 
  mutate(
    restecg = factor(case_when(
      # because we had too few missing values we 
      # replaced them with the mode value 
      is.na(restecg) ~ "0",
      TRUE ~ restecg
    )
    ))

df_naplot <- vis_miss(df)

```

```{r report table}
df_datatypes = vapply(colnames(df),FUN = function(x){
  paste(class(df[[x]]), collapse = ", ")
}, FUN.VALUE = character(1)
  )

# For report table
df_exp = c(
  "age"      = "Age in years",
  "sex"      = "Sex (1 = male; 0 = female)",
  "cp"       = "Chest pain type (1: typical, 2: atypical, 3: non-anginal, 4: asymptomatic)",
  "trestbps" = "Resting blood pressure (in mm Hg on admission)",
  "chol"     = "Serum cholestoral in mg/dl",
  "fbs"      = "Fasting blood sugar > 120 mg/dl (1 = true; 0 = false)",
  "restecg"  = "Resting electrocardiographic results",
  "thalach"  = "Maximum heart rate achieved",
  "exang"    = "Exercise induced angina (1 = yes; 0 = no)",
  "oldpeak"  = "ST depression induced by exercise relative to rest",
  "slope"    = "The slope of the peak exercise ST segment",
  "ca"       = "Number of major vessels (0-3) colored by flourosopy",
  "thal"     = "Thalassemia (3 = normal; 6 = fixed defect; 7 = reversable defect)",
  "num"      = "Diagnosis of heart disease (angiographic disease status)"
)


df_feat = c(rep("feature", 13),
                "target"
)

df_na_vals <- sapply(colnames(df),
         function(x)(100*(round(mean(is.na(df[[x]])), 2)))
)

df_str_table <- data.frame(
  Variables = names(df_exp),
  datatypes = df_datatypes,
  `feature/target` = df_feat,
  explanation = df_exp,
  `Missing Value (in%)` = df_na_vals,
  row.names = c(1:length(df_exp)),
  check.names = F
)

df_str_table[3, 2, 5, 6, 8] = "factor"
df_str_table[11] =  "ordered, factor"

df_str_table <- df_str_table %>% 
  arrange(desc(`Missing Value (in%)`)) %>% 
  mutate(
    `Missing Value (in%)` = paste0(`Missing Value (in%)`, "%")
  )


gg_table_form <- df_str_table %>%
  kbl(format = "html",
      align = "l") %>% 
  kable_styling(bootstrap_options = c("strip", "bordered", "condensed"))%>%
  kable_classic(full_width = F, html_font = "Cambria")

```

```{r Wrangling Data}

                                  #### ----------------- Data Cleaning ------------------- ####


wrangle <- function(path = PATH){

  df2 <- read.csv(PATH)
                                                        
###
#---
### wrangling

  df2 <- df2 %>% 
    select(-all_of(c("thal", "ca", "slope", "chol")))
  
  df2 <- df2 %>% 
    mutate(across(
      .cols = everything(),
      function(x){
        case_when(x %in% c("?", "-9") ~ NA,
                  TRUE ~ x)
      }
    )) %>% 
    mutate(across(
      .cols = everything(), as.numeric
    ))

  df2 <- df2 %>% 
    mutate(
      across(
        .cols = c("sex", "fbs", "restecg", "exang", "cp"),
        ~ factor(.)
      )
    )

  df2$num = factor(df2$num, levels = c(0, 1, 2, 3, 4), ordered = T)
  
  ## Basic NA imputation using mode
  df2$restecg <- factor(df2$restecg,
                      levels = c(0, 1, 2))
  
  
  df2 <- df2 %>% 
    mutate(
      restecg = factor(case_when(
        is.na(restecg) ~ "0",
        TRUE ~ restecg
      )
      ))

  ####
  
  ### 
  # --- splitting data randomly
  
  ###
  set.seed(1000)
  df2_scramble <- sample(c(1:920), 920)

  df2 <- df2[df2_scramble,]
  rownames(df2) <- c(1:nrow(df2))
  return(df2)
}
```
                                          
```{r Split data}
df2 <- wrangle(PATH)
train_dat <- df2[121:nrow(df2),]
test_dat <- df2[1:120, ]

save(test_dat, file = "test.RData")
write.csv(test_dat, file = "CSV_datasets/test.csv")

save(train_dat, file = "train.RData")
write.csv(train_dat, file = "CSV_datasets/train.csv")
```

```{r, Basic NA imputation}

df2 <- train_dat
my_colnames = colnames(df2)

par(mfrow = c(1, 1))

unique(df2$restecg)

df2$restecg <- factor(df2$restecg,
                      levels = c(0, 1, 2))

```

```{r}
                                              #### --------------- Normality and Balanced Distribution test ---------------- ####
rest_ecg_dist <-  df2 %>% 
  ggplot(aes(restecg)) +
  geom_bar()+
  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
  theme_bw() +
  labs(title = "Distribution of Resting ECG Results") +
  theme(plot.title = element_text(hjust = 0.5))

```

```{r}
rest_ecg_dist
```

```{r Checking with bars}


# We know by design all observations are independent
# Checking if the proportions are plausible

cat_cols <- my_colnames[sapply(my_colnames, function(x)(is.factor(df2[[x]])))]

bars <- list() 

for (cat_col in cat_cols){
  
  bars[[cat_col]] <- ggplot(df2, aes(.data[[cat_col]])) +
    geom_bar() +
    scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
    theme_bw() +
    labs(title = paste0("Distribution of ", cat_col))
}

bars = wrap_plots(bars, ncol = 3)

```

```{r Checking with hists}

# Checking for normality

par(mfrow = c(2, 2))
num_cols <- my_colnames[sapply(my_colnames, function(x)!(is.factor(df2[[x]])))]

hists = list()
for (num_col in num_cols){
  
  hists[[num_col]] <- ggplot(df2, aes(.data[[num_col]])) +
    geom_histogram() +
    scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
    theme_bw() +
    labs(title = paste0("Distribution of ", num_col))
}

hists = wrap_plots(hists, ncol = 2)

rm(cat_col, cat_cols, train_dat, test_dat, num_col, num_cols)
```

```{r Imputations rf}
                                                  ####  ---------------- Mice Imputation ----------------- ####

features = c( "trestbps", "thalach", "exang", "oldpeak")

predictors = colnames(df2)[!(colnames(df2) %in% features)]

imputed_dat <- df2

my_colnames = colnames(imputed_dat)  

my_colnames[sapply(my_colnames, function(x)(is.factor(df2[[x]])))]

# We used predictive mean matching for numerical variables
# and Random forest for categorical variables in our first mice model.

mtd = c("pmm", "rf")

methods_vector = c(
  age = mtd[1],
  sex = mtd[2],
  cp = mtd[2],
  trestbps = mtd[1],
  fbs = mtd[2],
  restecg = mtd[2],
  thalach = mtd[1],
  exang = mtd[2],
  oldpeak = mtd[1],
  num = mtd[2]
)

na_cols <- colSums(is.na(imputed_dat))
my_sequence = names(sort(na_cols))


imputed_rf <- mice(imputed_dat, m = 5,
                   method = methods_vector,
                   maxit = 15,
                   visitSequence = my_sequence, seed = 1000)

```

```{r imputation lr}

# Our second mice model.
mtds = c("pmm", "logreg", "polyreg", "polyr")

methods_vector_lr <- c(
  age = mtds[1],
  sex = mtds[2],
  cp = mtds[3],
  trestbps = mtds[1],
  fbs = mtds[2],
  restecg = mtds[3],
  thalach = mtds[1],
  exang = mtds[2],
  oldpeak = mtds[1],
  num = mtds[4]
)


imputed_lr <- mice(imputed_dat, m = 5,
                   method = methods_vector_lr,
                   maxit = 15,
                   visitSequence = my_sequence, seed = 1000)

```

```{r Imputation validity}

## Checking validity of my MICE model

#density plots
densityplot_rf <- densityplot(imputed_rf, main = "imputed_rf")
densityplot_lr <-  densityplot(imputed_lr, main = "imputed_lr")

#stripplots
striplt_rf <- stripplot(imputed_rf, fbs + exang ~ .imp, main = "imputed rf")
striplt_lr <- stripplot(imputed_lr, fbs + exang ~ .imp, main = "imputed lr")

#traceplots
traceplt_rf <- plot(imputed_rf, main = "imputed_rf")
traceplt_lr <-  plot(imputed_lr, main = "imputed_lr")

```
                              #### ------------- Parallel Line Assunption Testing ------------- ####
```{r testing POLR assumptions}
dat <- mice::complete(imputed_lr, 1)

#1. Proportional Odds / Parallel Lines Assumption (PLA)

test_fit <- MASS::polr(num ~ age + sex + cp + trestbps +
                   fbs + restecg + thalach + exang + oldpeak, 
                 data = dat, Hess = TRUE)

## brant test to check PLAfile:///C:/Users/Amir/Downloads/A.15.pdf

brant_result <- brant(test_fit)
brant_result[, "probability"] = round(brant_result[, "probability"], 2)
p1 = list()

p1[[1]] <- dat %>% 
  filter(!(is.na(exang) | is.na(num))) %>% 
  count(exang, num) %>% 
  ggplot(aes(exang, n, fill = num)) + 
  geom_col(position = "fill")

p1[[2]] <- dat %>% 
  filter(!(is.na(sex) | is.na(num))) %>% 
  count(sex, num) %>% 
  ggplot(aes(sex, n, fill = num)) + 
  geom_col(position = "fill")

p1[[3]] <- dat %>% 
  ggplot(aes(x = num, y = age)) +
  geom_boxplot(varwidth = T)

#To compare with a pval > 0.05 var

p1[[4]] <- dat %>% 
  ggplot(aes(x = num, y = trestbps)) +
  geom_boxplot(varwidth = T)

assumption_check_plot <- wrap_plots(p1, ncol = 2)

# PLA failed!!

```

```{r PPO model}

fit_ppo <- with(imputed_rf, 
                vglm(num ~ age + sex + cp +
                           trestbps + fbs + restecg +
                           thalach + exang + oldpeak, 
                     family = cumulative(parallel = FALSE ~ age + restecg + exang)))

```

```{r Rubins Rule}
                      #### ---------------- Pooling coefficients --------------  ####
# Use Rubins Rule to pool our model

analyses <- fit_ppo$analyses

all_coefs <- sapply(analyses, coef)
all_var_est <- lapply(analyses, vcov)
imp_m <- imputed_lr$m

# pooled estimate

pooled_coefs <- rowMeans(all_coefs)

# within variance
u_var <- Reduce("+", all_var_est) / length(all_var_est)
u_var <- diag(u_var)

# between variance
b_var <- apply(all_coefs, 1, var)

#Vt = Vw + Vb + Vb/m

t_var = u_var + b_var + b_var/imp_m

###
pooled_se = sqrt(t_var)
z_score = pooled_coefs/ pooled_se
z_score

L = (b_var + b_var/imp_m)/t_var

dfo = (imp_m - 1)/L^2

vm = nrow(imputed_dat) - length(df)

dfobs = ((vm + 1)/(vm + 3)) * (vm * (1- L))
dfadj = (dfo * dfobs)/(dfo + dfobs)
dfadj = floor(dfadj)




ME = sapply(names(dfadj),
     function(x){
        qt(0.975, df = dfadj[[x]]) * pooled_se[[x]]
}
             )

ME = data.frame(
  Parameters = names(ME),
  `Margin of Error` = ME,
  check.names = F,
  row.names = 1:length(ME)
)

ME_table <- ME %>%
  kbl(format = "html",
      align = "l") %>% 
  kable_styling(bootstrap_options = c("strip", "bordered", "condensed"))%>%
  kable_classic(full_width = F, html_font = "Cambria")
```

```{r fit your final model}

final_model = analyses[[1]]
final_model@coefficients <- pooled_coefs
```

```{r }

load(file = "test.RData")

# To avoid data leakage
target = test_dat$num %>% unlist()
test_dat = test_dat[, 1:9]

# adjustment for sensitivity

weight_factor <- df2 %>% 
  group_by(num) %>% 
  summarise(
    perc. = round(n()/nrow(df2), 2)
  ) %>% 
  mutate(
    K = (1/(perc.)^(1/3))/1.3
  ) %>% select(K) %>% unlist()

###
test_imp <- mice(test_dat, m = 5, method = methods_vector[1:9],
                 maxit = 15,
                 visitSequence = my_sequence, seed = 1000)

test_dat <- mice::complete(test_imp, 1)

pred_probs <- VGAM::predictvglm(final_model, newdata = test_dat, type = "response")

weighted_probs <- sweep(pred_probs, MARGIN = 2, STATS = weight_factor, FUN = "*")

###
predicted_classes <- unname(apply(pred_probs, 1, which.max) - 1)
weighted_classes <- unname(apply(weighted_probs, 1, which.max) - 1)
actual_classes <- target
```

```{r Diagnost}
                               #### -----------------------Model Diagnosis ---------------------- ####
Diagnost = data.frame(
  pred = predicted_classes,
  real = as.numeric(actual_classes) - 1 # because R used the lvls which start from 1.
  
)

Diagnost <- Diagnost %>% 
  mutate(
    success = if_else(pred == real, T, F),
    bin_real = if_else(real == 0, T, F),
    bin_pred = if_else(pred == 0, T, F),
    abs_err = abs(pred - real),
    bin_accuracy = if_else(bin_real == bin_pred, "Correct", "Wrong")
  )



cat("D1\nAbsolute success Rate: ", mean(Diagnost$success),
    "\nBinary Accuracy Rate: ", mean(Diagnost$bin_accuracy == "Correct"),
    "\nMean Predictive Difference: ", mean(Diagnost$abs_err),
    "\nAverage L: ", -1 * mean(as.numeric(Diagnost$pred) - as.numeric(Diagnost$real)
                                    )
)

###
Diagnost2 = data.frame(
  pred = as.numeric(weighted_classes),
  real = as.numeric(actual_classes) - 1
)

Diagnost2 <- Diagnost2 %>% 
  mutate(
    success = if_else(pred == real, T, F),
    bin_real = if_else(real == 0, T, F),
    bin_pred = if_else(pred == 0, T, F),
    abs_err = abs(pred - real),
    bin_accuracy = if_else(bin_real == bin_pred, "Correct", "Wrong")
  )

cat("\nD2:\nAbsolute success Rate: ", mean(Diagnost2$success),
    "\nBinary Accuracy Rate: ", mean(Diagnost2$bin_accuracy == "Correct"),
    "\nMean Predictive Difference: ", mean(Diagnost2$abs_err),
    "\nAverage L: ", -1 * mean(as.numeric(Diagnost2$pred) - as.numeric(Diagnost$real)
                                    )
)


```

```{r Confusion Matrix}

OR <- exp(-pooled_coefs)
## Diagnostics of the model

  # Confusing matrix
  # 

real = factor(Diagnost$real,
              levels = c(0, 1, 2, 3, 4),
              labels = c(0, 1, 2, 3, 4))

pred = factor(Diagnost$pred,
              levels = c(0, 1, 2, 3, 4),
              labels = c(0, 1, 2, 3, 4))

pred2 = factor(Diagnost2$pred,
              levels = c(0, 1, 2, 3, 4),
              labels = c(0, 1, 2, 3, 4))

bin_real = factor(Diagnost$bin_real,
              levels = c(T, F),
              labels = c("Healthy", "Sick")
                  )


bin_pred = factor(Diagnost$bin_pred,
              levels = c(T, F),
              labels = c("Healthy", "Sick")
                  )

bin_pred2 = factor(Diagnost2$bin_pred,
              levels = c(T, F),
              labels = c("Healthy", "Sick")
                  )

model_cm <- confusionMatrix(real, pred)
results_diag <- round(model_cm$byClass, 2)

model_cm2 <- confusionMatrix(real, pred2)
results_diag2 <- round(model_cm2$byClass, 2)


bin_model_cm <- confusionMatrix(bin_real, bin_pred)
bin_model_cm2 <-  confusionMatrix(bin_real, bin_pred2)

bin_model_cm <- data.frame(Metrics = names(bin_model_cm$byClass),
                            Values = round(bin_model_cm$byClass, 2))%>% 
  pivot_wider(names_from = Metrics, values_from = Values)

bin_model_cm2 <- data.frame(Metrics = names(bin_model_cm2$byClass),
                            Values = round(bin_model_cm2$byClass, 2)
) %>% 
  pivot_wider(names_from = Metrics, values_from = Values)


```

## Purpose

This report documents the internal validation of a prediction model using Kaggle UCI Heart Disease data set. It aims to check the validity for both binary and 5-level ordinal classification.

## Brief Summary

This analysis predicts heart disease (CAD) using the [Kaggle UCI Heart Disease data set](https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset). Key steps performed include:

-   Data cleaning and mice imputation We used Predictive Mean Matching for numerical variables and random forest for categorical variables after cross comparing the imputation results with logistic regression.

-   Testing parallel assumption test (violated) We used Brant's test and visualizations to test the assumptions.

-   Built a model using a Partial Proportional Odds logistic. Regression.

-   Used Rubin's Rule to get pooled estimates for our model

-   Built a binary and 5-level ordinal model to classify sick and healthy.

-   Added a weighted factor (w)

    $w = \frac{1}{1.3 \cdot p^{1/3}}$

    where p is the class proportion

-   to the predictive value matrix to increase the weight of higher class values.

## Results

Our model failed to identify disease severity. Although the mean absolute error was below 0.5 (0.16), our multinomial model failed to identify class 4 and poorly performed on class 2 due to insufficient training samples. Class 4 had three values

```{r, include=TRUE}
load("test.RData")
load("train.RData")

dt1 <- train_dat %>% 
  count(num) %>% 
  rename("Class" =  "num", "Observations-train" = "n")

dt2 <- test_dat %>% 
  count(num) %>% 
  rename("Class" =  "num", "Observations-test" = "n") %>% 
  select(-Class)

dt1 %>% cbind(dt2) %>%
  kbl(format = "html",
      caption = "Class Counts for our Target Variable in Test and Training data sets",
      align = "l") %>% 
  kable_styling(bootstrap_options = c("strip", "bordered", "condensed"))%>%
  kable_classic(full_width = F, html_font = "Cambria")

```

```{r, include = TRUE}
round(model_cm2$byClass, 2) %>% 
  kbl(format = "html",
      caption = "Confusion matrix for our weighted model\n(Multinomial prediction)",
      align = "l") %>% 
  kable_styling(bootstrap_options = c("strip", "bordered", "condensed"))%>%
  kable_classic(full_width = F, html_font = "Cambria")


bin_model_cm2 %>% 
  kbl(format = "html",
      caption = "Confusion matrix for our weighted model\n Binomial Prediction(Healthy and Sick)",
      align = "l") %>% 
  kable_styling(bootstrap_options = c("strip", "bordered", "condensed"))%>%
  kable_classic(full_width = F, html_font = "Cambria")
```

## References

1.  Heymans MW, Eekhout I. (2019). *Applied Missing Data Analysis*. Amsterdam: VU University.

2.  Kaggle. (2019). UCI Heart Disease Dataset. <https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset>

3.  ArÄ± E. (2014). Parallel Lines Assumption in Ordinal Logistic Regression and Analysis Approaches. *International Interdisciplinary Journal of Scientific Research*, 1:8-23.
